---
title: "Lecture 3 MATH 390.4 Queens College"
author: "Professor Adam Kapelner"
date: "February 5, 2018"
---

## First modeling exercise

Before we model, let's fabricate the training data! Let's try to build a data matrix similar to the one in the class example. Let's imagine $n = 100$ and $x_1$ is salary, $x_2$ is a dummy variable for missing loan payment in their credit history, $x_3$ is a ordinal variable for crime type coded 0, 1, 2 or 3.

We can "make up" a dataset using the sampling we just learned.

```{r}
n = 100 #number of historical objects: the people
p = 3 #number of features about each

X = matrix(NA, nrow = n, ncol = p)
X
```

Why should we fill up this matrix with NA's? No technical reason; it is done for a practical reason. Every value is currently "missing" until it's filled in i.e. it will let you know if you didn't fill any of the values.

We can also name rows and columns. Each row is a historical person and each column is a feature about that person.

```{r}
colnames(X) = c(
  "salary", 
  "has_past_unpaid_loan", 
  "past_crime_severity"
)
fake_first_names = c(
  "Sophia", "Emma", "Olivia", "Ava", "Mia", "Isabella", "Riley", 
  "Aria", "Zoe", "Charlotte", "Lily", "Layla", "Amelia", "Emily", 
  "Madelyn", "Aubrey", "Adalyn", "Madison", "Chloe", "Harper", 
  "Abigail", "Aaliyah", "Avery", "Evelyn", "Kaylee", "Ella", "Ellie", 
  "Scarlett", "Arianna", "Hailey", "Nora", "Addison", "Brooklyn", 
  "Hannah", "Mila", "Leah", "Elizabeth", "Sarah", "Eliana", "Mackenzie", 
  "Peyton", "Maria", "Grace", "Adeline", "Elena", "Anna", "Victoria", 
  "Camilla", "Lillian", "Natalie", "Jackson", "Aiden", "Lucas", 
  "Liam", "Noah", "Ethan", "Mason", "Caden", "Oliver", "Elijah", 
  "Grayson", "Jacob", "Michael", "Benjamin", "Carter", "James", 
  "Jayden", "Logan", "Alexander", "Caleb", "Ryan", "Luke", "Daniel", 
  "Jack", "William", "Owen", "Gabriel", "Matthew", "Connor", "Jayce", 
  "Isaac", "Sebastian", "Henry", "Muhammad", "Cameron", "Wyatt", 
  "Dylan", "Nathan", "Nicholas", "Julian", "Eli", "Levi", "Isaiah", 
  "Landon", "David", "Christian", "Andrew", "Brayden", "John", 
  "Lincoln"
)
rownames(X) = fake_first_names
X
```

Let's pretend "salary" is normally distributed with mean \$50,000 and standard error \$20,000. Let's make up some data

```{r}
X[, 1] = round(rnorm(n, 50000, 20000))
X
#another way to set this feature:
X[, "salary"] = round(rnorm(n, 50000, 20000))
X
```

Are the salary values independent? Yes, or at least we assume so... Hopefully we will get to models in this semester where they are not independent.

We will eventually do visualization, but first let's take a look at a summary of this data:

```{r}
summary(X[, "salary"])
```

Let's pretend "has_past_unpaid_loan" is benoulli distributed with probability 0.2

```{r}
X[, "has_past_unpaid_loan"] = rbinom(n, size = 1, prob = 0.2)
X
```

Is this a reasonable fabrication of this dataset? No... since salary and not paying back a loan are dependent r.v.'s. But... we will ignore this now.

It would be nice to see a summary of values. Would median and mean be appropriate here? No. For categorical variables, you should "table" them:

```{r}
table(X[, "has_past_unpaid_loan"])
```


Also, 50\% of people have no crime, 40\% have an infraction, 8\% a misdimeanor and 2\% a felony. Let's try to add this to the matrix. We first need to simulate this. Here's how:

```{r}
X[, "past_crime_severity"] = sample(
  c("no crime", "infraction", "misdimeanor", "felony"),
  size = n,
  replace = TRUE,
  prob = c(.50, .40, .08, .02)
)
X
```

Oh no - what happened?? Our matrix went all characters... The matrix type cannot handle numeric and categorical variables simultaneously! It would be nice to keep factor or character information in a matrix but this is not the spec.

Enter the key data type, the "data.frame" - this is the object that is used for modeling in the R ecosystem. It is essentially an upgraded matrix.

```{r}
X = data.frame(
  salary = round(rnorm(n, 50000, 20000)),
  has_past_unpaid_loan = rbinom(n, size = 1, prob = 0.2),
  past_crime_severity = sample(
    c("no crime", "infraction", "misdimeanor", "felony"),
    size = n,
    replace = TRUE,
    prob = c(.50, .40, .08, .02)
  )
)
row.names(X) = fake_first_names
X
```

RStudio gives us a nicer rendering of the information. You can open it up in a separate tab via:

```{r}
View(X)
```

and you can view summaries of each feature via

```{r}
summary(X)
```

Again, summary doesn't work for "has_past_unpaid_loan". We should convert it to factor and try again. Note the "$" operator which is now valid for data.frame objects.

```{r}
X$has_past_unpaid_loan = factor(X$has_past_unpaid_loan, labels = c("Never", ">=1"))
head(X) #make sure that worked
summary(X) #much better now!
```

We are soon going to upgrade data.frame to data.table which gives us powerful, lightning-fast operations on our tables.

In our training set D, we are missing one final variable, the response! Let's add it and say that 90\% of people are creditworthy i.e. they paid back their loan:

```{r}
X$paid_back_loan = factor(rbinom(n, size = 1, prob = 0.9), labels = c("No", "Yes"))
head(X) #make sure that worked
summary(X) #much better now!
```

Conceptually - why does this make no sense at all??? y is independent of X --- what happens then? No function f can ever have any predictive / explanatory power! This is just a silly example to show you the data types. We will work with real data soon. Don't worry.

Note that our matrix is now no longer just $X$; it includes $y$. I could make a renamed copy, but I want to show off dropping this column and create a new object that's both features and response column-binded together:

```{r}
y = X$paid_back_loan
X$paid_back_loan = NULL #drop column
Xy = cbind(X, y) 
head(Xy) #make sure that worked
summary(Xy) #much better now!
#Note: Xy = X; rm(X) would've been easier
```

I prefer calling the full training set ${X, y}$ a data frame called $Xy$. The object $X$ is now extraneous, so we should clean up our workspace now.

```{r}
rm(list = setdiff(ls(), "Xy"))
```

## Computer Science Sidebar

Before we get back to modeling, it is worth knowing a couple more data structures in R. These are not "data [science] types", these are "[computer science] data types". 

The first is arrays i.e. are multidimensional vectors

```{r}
x = array(1 : 5, 5)
x
X = array(1 : 25, c(5, 5))
X
X = array(1 : 125, c(5, 5, 5))
X
```

The second are "lists" which are hashmaps or dictionaries. if You don't know what this is, you should read about this online as it should have been covered in a intro to CS class.

```{r}
dict = list()
dict$a = "first"
dict$b = "second"
dict
length(dict)
dict$a
dict[["a"]]
dict[1] #subset of a hash
class(dict[1])
```

Lists conveniently allow all sorts of data types.

```{r}
varied_dict = list()
varied_dict$a = "first"
dict$b = 2
dict$c = 1 : 7
dict$d = matrix(NA, nrow = 2, ncol = 2)
dict$e = function(x){x^2}
dict
length(dict)
```

They have lots of uses in data science applications. We will likely see them in class and if not, you'll definitely see them in the real world.

```{r}
rm(list = setdiff(ls(), "Xy")) #cleanup again
```

## Back to modeling

